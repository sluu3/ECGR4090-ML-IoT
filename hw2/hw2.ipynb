{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "interested-lambda",
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1.14.0\n"
     ]
    }
   ],
   "source": [
    "# TensorFlow and tf.keras\n",
    "import tensorflow as tf\n",
    "\n",
    "# Helper libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras import Input, layers\n",
    "\n",
    "\n",
    "print(tf.__version__)\n",
    "\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "\n",
    "(train_data, train_label), (test_data, test_label) = cifar10.load_data()\n",
    "class_names = ['airplane','automobile','bird','cat','deer','dog','frog','horse','ship','truck']\n",
    "\n",
    "train_data = train_data / 255\n",
    "test_data = test_data / 255\n",
    "\n",
    "train_label = train_label.squeeze()\n",
    "test_label = test_label.squeeze()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_26\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d_28 (Conv2D)           (None, 16, 16, 32)        896       \n_________________________________________________________________\nmax_pooling2d_5 (MaxPooling2 (None, 8, 8, 32)          0         \n_________________________________________________________________\nconv2d_29 (Conv2D)           (None, 4, 4, 64)          18496     \n_________________________________________________________________\nflatten_5 (Flatten)          (None, 1024)              0         \n_________________________________________________________________\ndense_10 (Dense)             (None, 1024)              1049600   \n_________________________________________________________________\ndense_11 (Dense)             (None, 10)                10250     \n=================================================================\nTotal params: 1,079,242\nTrainable params: 1,079,242\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Part 5 of Hw\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3,3), strides = (2,2), padding = 'same', activation = 'relu', input_shape = (32, 32, 3)))\n",
    "model.add(MaxPooling2D(pool_size = (2,2), strides = (2,2)))\n",
    "model.add(Conv2D(64, (3,3), strides = (2,2), padding = 'same', activation = 'relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024, activation = 'relu'))\n",
    "model.add(Dense(10))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 29s 584us/sample - loss: 1.4389 - acc: 0.4820 - val_loss: 1.1855 - val_acc: 0.5709\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 30s 594us/sample - loss: 1.0936 - acc: 0.6124 - val_loss: 1.0414 - val_acc: 0.6258\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 32s 645us/sample - loss: 0.9345 - acc: 0.6714 - val_loss: 0.9919 - val_acc: 0.6518\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 32s 641us/sample - loss: 0.7977 - acc: 0.7200 - val_loss: 0.9310 - val_acc: 0.6770\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 32s 632us/sample - loss: 0.6737 - acc: 0.7633 - val_loss: 0.9361 - val_acc: 0.6795\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 32s 639us/sample - loss: 0.5545 - acc: 0.8074 - val_loss: 0.9225 - val_acc: 0.6885\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 32s 649us/sample - loss: 0.4332 - acc: 0.8496 - val_loss: 1.0037 - val_acc: 0.6845\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 32s 641us/sample - loss: 0.3236 - acc: 0.8897 - val_loss: 1.1040 - val_acc: 0.6884\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 32s 638us/sample - loss: 0.2319 - acc: 0.9203 - val_loss: 1.2722 - val_acc: 0.6717\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 33s 654us/sample - loss: 0.1736 - acc: 0.9421 - val_loss: 1.3448 - val_acc: 0.6784\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 32s 648us/sample - loss: 0.1366 - acc: 0.9536 - val_loss: 1.4836 - val_acc: 0.6839\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 30s 596us/sample - loss: 0.1110 - acc: 0.9622 - val_loss: 1.6786 - val_acc: 0.6767\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 26s 518us/sample - loss: 0.1014 - acc: 0.9646 - val_loss: 1.8266 - val_acc: 0.6741\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 26s 517us/sample - loss: 0.0853 - acc: 0.9712 - val_loss: 1.8416 - val_acc: 0.6662\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 26s 519us/sample - loss: 0.0884 - acc: 0.9704 - val_loss: 1.8834 - val_acc: 0.6677\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 26s 516us/sample - loss: 0.0751 - acc: 0.9751 - val_loss: 2.0167 - val_acc: 0.6785\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 26s 518us/sample - loss: 0.0729 - acc: 0.9762 - val_loss: 2.1264 - val_acc: 0.6736\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 26s 524us/sample - loss: 0.0750 - acc: 0.9741 - val_loss: 2.3066 - val_acc: 0.6598\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 29s 574us/sample - loss: 0.0691 - acc: 0.9760 - val_loss: 2.2379 - val_acc: 0.6770\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 30s 605us/sample - loss: 0.0641 - acc: 0.9790 - val_loss: 2.3585 - val_acc: 0.6763\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 39s 780us/sample - loss: 0.0588 - acc: 0.9807 - val_loss: 2.5039 - val_acc: 0.6711\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 38s 765us/sample - loss: 0.0668 - acc: 0.9777 - val_loss: 2.5251 - val_acc: 0.6635\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 34s 674us/sample - loss: 0.0572 - acc: 0.9811 - val_loss: 2.5927 - val_acc: 0.6766\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 40s 805us/sample - loss: 0.0611 - acc: 0.9800 - val_loss: 2.5888 - val_acc: 0.6688\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 34s 680us/sample - loss: 0.0524 - acc: 0.9828 - val_loss: 2.7017 - val_acc: 0.6758\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 32s 633us/sample - loss: 0.0637 - acc: 0.9801 - val_loss: 2.7027 - val_acc: 0.6653\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 30s 600us/sample - loss: 0.0510 - acc: 0.9833 - val_loss: 2.8134 - val_acc: 0.6719\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 29s 578us/sample - loss: 0.0564 - acc: 0.9818 - val_loss: 2.9128 - val_acc: 0.6628\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 30s 608us/sample - loss: 0.0521 - acc: 0.9832 - val_loss: 2.8962 - val_acc: 0.6623\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 32s 635us/sample - loss: 0.0553 - acc: 0.9823 - val_loss: 2.9740 - val_acc: 0.6696\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 30s 594us/sample - loss: 0.0473 - acc: 0.9854 - val_loss: 3.0814 - val_acc: 0.6633\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 30s 601us/sample - loss: 0.0512 - acc: 0.9843 - val_loss: 3.1157 - val_acc: 0.6661\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 29s 589us/sample - loss: 0.0498 - acc: 0.9837 - val_loss: 3.2861 - val_acc: 0.6630\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 31s 619us/sample - loss: 0.0558 - acc: 0.9829 - val_loss: 3.1355 - val_acc: 0.6707\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 29s 585us/sample - loss: 0.0465 - acc: 0.9856 - val_loss: 3.2772 - val_acc: 0.6776\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 29s 581us/sample - loss: 0.0503 - acc: 0.9849 - val_loss: 3.3193 - val_acc: 0.6766\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 30s 593us/sample - loss: 0.0464 - acc: 0.9856 - val_loss: 3.4143 - val_acc: 0.6616\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 31s 613us/sample - loss: 0.0572 - acc: 0.9838 - val_loss: 3.4505 - val_acc: 0.6655\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 29s 586us/sample - loss: 0.0475 - acc: 0.9858 - val_loss: 3.5083 - val_acc: 0.6622\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 30s 590us/sample - loss: 0.0455 - acc: 0.9862 - val_loss: 3.5465 - val_acc: 0.6714\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 27s 542us/sample - loss: 0.0496 - acc: 0.9861 - val_loss: 3.5624 - val_acc: 0.6686\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 31s 622us/sample - loss: 0.0510 - acc: 0.9850 - val_loss: 3.6390 - val_acc: 0.6698\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 30s 599us/sample - loss: 0.0456 - acc: 0.9863 - val_loss: 3.7274 - val_acc: 0.6726\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 32s 637us/sample - loss: 0.0399 - acc: 0.9877 - val_loss: 3.7524 - val_acc: 0.6739\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 31s 610us/sample - loss: 0.0484 - acc: 0.9863 - val_loss: 3.8729 - val_acc: 0.6755\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 30s 603us/sample - loss: 0.0472 - acc: 0.9874 - val_loss: 4.0068 - val_acc: 0.6706\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 29s 588us/sample - loss: 0.0497 - acc: 0.9860 - val_loss: 3.8289 - val_acc: 0.6759\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 30s 600us/sample - loss: 0.0463 - acc: 0.9872 - val_loss: 4.0351 - val_acc: 0.6771\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 30s 600us/sample - loss: 0.0425 - acc: 0.9884 - val_loss: 4.1052 - val_acc: 0.6757\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 30s 593us/sample - loss: 0.0407 - acc: 0.9885 - val_loss: 4.1350 - val_acc: 0.6709\n",
      "10000/10000 - 1s - loss: 4.1350 - acc: 0.6709\n",
      "\n",
      "Test accuracy:  0.6709\n"
     ]
    }
   ],
   "source": [
    "# Part 6 of HW\n",
    "\n",
    "model.compile(optimizer='adam', \n",
    "                loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                metrics=['accuracy'])\n",
    "train_hist = model.fit(train_data, train_label, epochs=50, validation_data=(test_data, test_label))\n",
    "test_lost, test_acc = model.evaluate(test_data, test_label, verbose=2)\n",
    "print('\\nTest accuracy: ', test_acc)\n",
    "\n",
    "\n",
    "# With 50 epochs: train acc: 96.8%, validation acc = 68.85%, test acc = 67.09%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[-0.0195881  -0.06554092 -0.07038189  0.09758257  0.19204696 -0.12794052\n  -0.0240816  -0.14869104  0.11007508  0.05478565]]\n[4]\n"
     ]
    }
   ],
   "source": [
    "# Part 7 of Hw\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "test_image = image.load_img('little-dog.jpg', target_size=(32,32))\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.array([test_image / 255.0])\n",
    "\n",
    "predict = model.predict(test_image, batch_size=1)\n",
    "print(predict)\n",
    "predict_class = model.predict_classes(test_image, batch_size=1)\n",
    "print(predict_class)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_28\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndepthwise_conv2d_29 (Depthwi (None, 16, 16, 3)         30        \n_________________________________________________________________\nconv2d_32 (Conv2D)           (None, 8, 8, 32)          896       \n_________________________________________________________________\ndepthwise_conv2d_30 (Depthwi (None, 4, 4, 32)          320       \n_________________________________________________________________\nconv2d_33 (Conv2D)           (None, 4, 4, 64)          2112      \n_________________________________________________________________\nmax_pooling2d_7 (MaxPooling2 (None, 2, 2, 64)          0         \n_________________________________________________________________\nflatten_7 (Flatten)          (None, 256)               0         \n_________________________________________________________________\ndense_14 (Dense)             (None, 1024)              263168    \n_________________________________________________________________\ndense_15 (Dense)             (None, 10)                10250     \n=================================================================\nTotal params: 276,776\nTrainable params: 276,776\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Part 8 of Hw\n",
    "\n",
    "new_model = Sequential()\n",
    "\n",
    "new_model.add(tf.keras.layers.DepthwiseConv2D(kernel_size= (3,3), strides= (2,2), padding= 'same', input_shape = (32, 32, 3)))\n",
    "new_model.add(Conv2D(32, (3,3), strides = (2,2), padding = 'same', activation = 'relu'))\n",
    "new_model.add(tf.keras.layers.DepthwiseConv2D(kernel_size= (3,3), strides= (2,2), padding= 'same'))\n",
    "new_model.add(Conv2D(64, (1,1), strides = (1,1), padding = 'same', activation = 'relu'))\n",
    "\n",
    "\n",
    "new_model.add(MaxPooling2D(pool_size = (2,2), strides = (2,2)))\n",
    "new_model.add(Flatten())\n",
    "new_model.add(Dense(1024, activation = 'relu'))\n",
    "new_model.add(Dense(10))\n",
    "\n",
    "new_model.summary()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}